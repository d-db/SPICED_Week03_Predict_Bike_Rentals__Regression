{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction to this notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook I will try to improve the results of my model through 'Hyperfeature Optimization'.\n",
    "The R2-score of the current model with 'Linear Regression' was 0.82."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "\n",
    "# new utils\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# to visualize the column transformer and pipeline\n",
    "set_config(display='diagram')\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/bike-sharing-demand/train.csv\", parse_dates=True, index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Define the preprocessing pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define a function to extract year, month and hour\n",
    "def extract_year_month_hour(df):\n",
    "    df = df.copy()\n",
    "    df[\"year\"] = df.index.year\n",
    "    df[\"month\"] = df.index.month\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def feature_expansion(df, column, degree):\n",
    "    df = df.copy()\n",
    "    for i in range(2,degree+1):\n",
    "        df[f\"{column}^{i}\"] = df[column] ** i\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "preprocessor_1 = (FunctionTransformer(extract_year_month_hour))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "preprocessor_2 = (FunctionTransformer(feature_expansion, validate=False, kw_args={'column': 'hour', \"degree\": 3}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "numeric_features = [\"atemp\", \"humidity\", \"windspeed\"]\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "categorical_features = [\"season\", \"holiday\", \"workingday\", \"weather\", \"year\", \"month\", \"hour\", \"hour^2\", \"hour^3\"]\n",
    "categorical_transformer = OneHotEncoder()\n",
    "\n",
    "#hour_transformer = KBinsDiscretizer(n_bins=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "preprocessor_3 = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "preprocessing_pipeline = Pipeline(steps=[\n",
    "    (\"Create_new_columns\", preprocessor_1),\n",
    "    (\"Feature_Expansion\", preprocessor_2),\n",
    "    (\"ColumnTransformer\", preprocessor_3)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Train/Test Split and apply data preprocessing pipeline to the train data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y = df[\"count\"]\n",
    "X = df.loc[:, df.columns != \"count\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "((8708, 10), (2178, 10), (8708,), (2178,))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 85)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "X_train_fe = preprocessing_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_fe = preprocessing_pipeline.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. CrossValidation and GridSearch to test and improve the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def cross_validation_regression(x_training_fe, y_training, n_cv=5, lasso_alpha=1):\n",
    "    \"\"\" Calculates the 'Train Score' and the mean of the 'Cross Validation' of the LinearRegression, Ridge and Lasso Model in order to assess the robustness of the model\n",
    "    :param x_training_fe: X_train dataset after Feature Engineering\n",
    "    :param y_training: y_train dataset\n",
    "    :param n_cv: Define n-fold cross validation splitting strategy. Default = 5\n",
    "    :param lasso_alpha: Define hyperparameter 'alpha' for the 'Lasso-Model'. Default = 1\n",
    "    :return: Prints the 'Train Score' and the mean of the 'Cross Validation'\n",
    "    \"\"\"\n",
    "\n",
    "    dic = {LinearRegression(): {\"Train Score\": 0, \"CV Mean\": 0},\n",
    "           Ridge(): {\"Train Score\": 0, \"CV Mean\": 0},\n",
    "           Lasso(alpha=lasso_alpha): {\"Train Score\": 0, \"CV Mean\": 0}\n",
    "           }\n",
    "\n",
    "    for model in dic.keys():\n",
    "        fitted_model = model.fit(x_training_fe, y_training)\n",
    "        cross_acc = cross_val_score(fitted_model,   # estimator: # the model you want to evaluate\n",
    "                                    x_training_fe,         # the training input data\n",
    "                                    y_training,         # the training output data\n",
    "                                    cv=n_cv,          # number of cross validation datasets\n",
    "                                    scoring='r2') # evaluation metric\n",
    "        dic[model][\"Train Score\"] = round(fitted_model.score(x_training_fe, y_training), 2)\n",
    "        dic[model][\"CV Mean\"] = round(cross_acc.mean(), 2)\n",
    "\n",
    "    print(f\"Linear Regression - Train Score:{dic[list(dic.keys())[0]]['Train Score']}, CV Mean:{dic[list(dic.keys())[0]]['CV Mean']}\\n\"\n",
    "          f\"Ridge             - Train Score:{dic[list(dic.keys())[1]]['Train Score']}, CV Mean:{dic[list(dic.keys())[1]]['CV Mean']}\\n\"\n",
    "          f\"Lasso             - Train Score:{dic[list(dic.keys())[2]]['Train Score']}, CV Mean:{dic[list(dic.keys())[2]]['CV Mean']}\")\n",
    "\n",
    "#Mean and STD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def grid_search_regression(x_training_fe, y_training, cv=5):\n",
    "    \"\"\"\n",
    "    Executes a GridSearchCV() for either LinearRegression(), Ridge() and Lasso()\n",
    "    :param x_training_fe: X_train dataset after Feature Engineering\n",
    "    :param y_training: y_train dataset\n",
    "    :return: The object of the choosen model with the optimized hyperparameters\n",
    "    \"\"\"\n",
    "    param_lr = {\n",
    "        'fit_intercept':[True,False],\n",
    "        'copy_X':[True, False]\n",
    "    }\n",
    "    param_ridge={\n",
    "        \"alpha\":[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        \"fit_intercept\":[True, False],\n",
    "        \"normalize\": [True, False],\n",
    "        \"copy_X\": [True, False],\n",
    "        \"solver\":[\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sag\", \"saga\", \"lbfgs\"]\n",
    "            }\n",
    "    param_lasso={\n",
    "        \"alpha\":[0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        \"fit_intercept\":[True, False],\n",
    "        \"copy_X\": [True, False],\n",
    "        \"warm_start\": [True, False]\n",
    "    }\n",
    "\n",
    "    user_input = input(\"On which model would you like to perform GridSearchCV() (LR/R/L - Q to stop)?: \")\n",
    "\n",
    "    if user_input == \"LR\":\n",
    "        a = LinearRegression()\n",
    "        param = param_lr\n",
    "    elif user_input == \"R\":\n",
    "        a = Ridge()\n",
    "        param = param_ridge\n",
    "    elif user_input == \"L\":\n",
    "        a = Lasso()\n",
    "        param = param_lasso\n",
    "    elif user_input == \"q\":\n",
    "        sys.exit(\"You have stopped the program\")\n",
    "\n",
    "    g = GridSearchCV(a, param, cv=cv, scoring='r2')\n",
    "    g.fit(x_training_fe, y_training)\n",
    "\n",
    "    return g.best_estimator_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - Train Score:0.89, CV Mean:0.89\n",
      "Ridge             - Train Score:0.85, CV Mean:0.85\n",
      "Lasso             - Train Score:0.89, CV Mean:0.89\n"
     ]
    }
   ],
   "source": [
    "cross_validation_regression(X_train_fe, np.log1p(y_train), lasso_alpha=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "You have stopped the program",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m You have stopped the program\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search_regression(X_train_fe, np.log1p(y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "Ridge(alpha=0.001, normalize=True)",
      "text/html": "<style>#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e {color: black;background-color: white;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e pre{padding: 0;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-toggleable {background-color: white;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-estimator:hover {background-color: #d4ebff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-item {z-index: 1;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-parallel-item:only-child::after {width: 0;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-3ce38958-1fed-42fb-84c6-5f02ba7b9e6e\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.001, normalize=True)</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"62af782b-c651-45c1-a697-2dd6ec5c1b96\" type=\"checkbox\" checked><label for=\"62af782b-c651-45c1-a697-2dd6ec5c1b96\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.001, normalize=True)</pre></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(X_train_fe, np.log1p(y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train R2-score of the linear regression is: 0.89\n",
      "The test R2-score of the linear regression is: 0.89\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"The train R2-score of the linear regression is: {round(best_model.score(X_train_fe,np.log1p(y_train)),2)}\n",
    "The test R2-score of the linear regression is: {round(best_model.score(X_test_fe,np.log1p(y_test)),2)}\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observation**:\n",
    "* The R2-score for the train-set has not changed"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
